{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "G_wBK3tCXBME"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e77822b11fa473bbe3113413cc2751d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aee7c5bb8d04b0c8b9250360a3273c0",
              "IPY_MODEL_288885328af843a383994c6c64c2b97a",
              "IPY_MODEL_7691bb49f9b64704ae278eb21c672b2c"
            ],
            "layout": "IPY_MODEL_ccf4a623ace54f9a98afad55b8fb0218"
          }
        },
        "2aee7c5bb8d04b0c8b9250360a3273c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d5224ed5394ccbac2f82d8b2decf62",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e73c19e0097b4c8e8028cbb1ad94d7a0",
            "value": "‚Äá‚Äá0%"
          }
        },
        "288885328af843a383994c6c64c2b97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30bb3e9526964488a70a5e897d9b4856",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d412ee453f14ad7b08ecb0cbd03e061",
            "value": 0
          }
        },
        "7691bb49f9b64704ae278eb21c672b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b63f89feaa04c29b51c43311cb683f9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1baaa449b6e642ebb77d9aea95a026c9",
            "value": "‚Äá0/5‚Äá[00:05&lt;?,‚Äá?it/s]"
          }
        },
        "ccf4a623ace54f9a98afad55b8fb0218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d5224ed5394ccbac2f82d8b2decf62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e73c19e0097b4c8e8028cbb1ad94d7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30bb3e9526964488a70a5e897d9b4856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d412ee453f14ad7b08ecb0cbd03e061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b63f89feaa04c29b51c43311cb683f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1baaa449b6e642ebb77d9aea95a026c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Musababdulrazaq/AsoSoft-TTS-Speech-Corpus-for-Central-Kurdish/blob/main/Copy_of_FakeYou_Tacotron2_Hi_Fi_GAN_(CPU).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><font color=\"pink\" size=\"+2\"> **FakeYou Tacotron 2 CPU Synthesis Colab**\n",
        "___\n",
        "\n",
        "Last update: 07/09/2023\n",
        "\n",
        "___\n",
        "\n",
        "### [Tacotron 2](https://github.com/NVIDIA/tacotron2)\n",
        "<a href=\"https://fakeyou.com/\"><img src=\"https://fakeyou.com/fakeyou/FakeYou-Logo.png\" alt=\"FakeYou Logo. Click here to go to the official website.\"></a>\n",
        "\n",
        "---\n",
        "\n",
        "## ü§ù**Credits**ü§ù\n",
        "Code originally created by `CookieGalaxy#8351` for the Pony Preservation Project\n",
        "\n",
        "Colab notebook prepared by `justinjohn-03`."
      ],
      "metadata": {
        "id": "htWUNWSCWKmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tacotron2 CPU Synthesizer**"
      ],
      "metadata": {
        "id": "iRlNbRilXdEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('secret_musab')"
      ],
      "metadata": {
        "id": "bz0s5p382OqI",
        "outputId": "be793823-7445-4949-c24d-32745a5b4b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'musab123'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MfDzBzUc_Sso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MNbgCkQW9YLV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RFESp5C__SPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zUtr31AL_Ry4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prep\n",
        "import os\n",
        "!pip install tqdm -q\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "from os.path import exists, join, basename, splitext\n",
        "!pip install resampy\n",
        "!pip install git+https://github.com/IAHispano/gdown.git\n",
        "git_repo_url = 'https://github.com/justinjohn0306/TTS-TT2.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "# clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  !git clone -q --recursive https://github.com/justinjohn0306/hifi-gan\n",
        "  !pip install -q unidecode\n",
        "import sys\n",
        "sys.path.append('hifi-gan')\n",
        "sys.path.append(project_name)\n",
        "\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "logging.getLogger('librosa').setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "#Universal HiFi-GAN (has some robotic noise): 1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown **The \"tacotron_id\" is where you can put a link to your trained tacotron2 model from Google Drive.**\n",
        "\n",
        "\n",
        "#@markdown If the audio sounds too artificial, you can lower the superres_strength\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Config:\n",
        "\n",
        "#@markdown Restart the runtime to apply any changes.\n",
        "\n",
        "tacotron_id = \"1-NDvTKw1908NCQarMCiEkw9dSGV3VsG6\" #@param {type:\"string\"}\n",
        "\n",
        "hifigan_id = \"universal\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown _leave blank or enter \"universal\" for universal model_\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "if tacotron_id != \"\":\n",
        "    TACOTRON2_ID = tacotron_id\n",
        "else:\n",
        "    raise Exception(\"No ID provided.\")\n",
        "\n",
        "if hifigan_id in {\"\", \"universal\"}:\n",
        "    HIFIGAN_ID = \"universal\"\n",
        "    print(\"Using universal Hifi-Gan model.\")\n",
        "else:\n",
        "    HIFIGAN_ID = hifigan_id\n",
        "\n",
        "# Check if Initialized\n",
        "try:\n",
        "    initialized\n",
        "except NameError:\n",
        "    print(\"Setting up, please wait.\\n\")\n",
        "    with tqdm(total=5, leave=False) as pbar:\n",
        "\n",
        "        import time\n",
        "        import matplotlib\n",
        "        import matplotlib.pylab as plt\n",
        "        import gdown\n",
        "        d = 'https://drive.google.com/uc?id='\n",
        "\n",
        "        %matplotlib inline\n",
        "        import IPython.display as ipd\n",
        "        import numpy as np\n",
        "        import torch\n",
        "        import json\n",
        "        from hparams import create_hparams\n",
        "        from model import Tacotron2\n",
        "        from layers import TacotronSTFT\n",
        "        from audio_processing import griffin_lim\n",
        "        from text import text_to_sequence\n",
        "        from env import AttrDict\n",
        "        from meldataset import mel_spectrogram, MAX_WAV_VALUE\n",
        "        from models import Generator\n",
        "        from denoiser import Denoiser\n",
        "        import resampy\n",
        "        import scipy.signal\n",
        "\n",
        "        pbar.update(1) # initialized Dependancies\n",
        "\n",
        "        graph_width = 900\n",
        "        graph_height = 360\n",
        "        def plot_data(data, figsize=(int(graph_width/100), int(graph_height/100))):\n",
        "            %matplotlib inline\n",
        "            fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
        "            for i in range(len(data)):\n",
        "                axes[i].imshow(data[i], aspect='auto', origin='lower',\n",
        "                            interpolation='none', cmap='inferno')\n",
        "            fig.canvas.draw()\n",
        "            plt.show()\n",
        "\n",
        "        # Setup Pronounciation Dictionary\n",
        "        !wget 'https://github.com/justinjohn0306/FakeYou-Tacotron2-Notebook/releases/download/CMU_dict/merged.dict.txt'\n",
        "        thisdict = {}\n",
        "        for line in reversed((open('merged.dict.txt', \"r\").read()).splitlines()):\n",
        "            thisdict[(line.split(\" \",1))[0]] = (line.split(\" \",1))[1].strip()\n",
        "\n",
        "        pbar.update(1) # Downloaded and Set up Pronounciation Dictionary\n",
        "\n",
        "        def ARPA(text, punctuation=r\"!?,.;\", EOS_Token=True):\n",
        "            out = ''\n",
        "            for word_ in text.split(\" \"):\n",
        "                word=word_; end_chars = ''\n",
        "                while any(elem in word for elem in punctuation) and len(word) > 1:\n",
        "                    if word[-1] in punctuation: end_chars = word[-1] + end_chars; word = word[:-1]\n",
        "                    else: break\n",
        "                try:\n",
        "                    word_arpa = thisdict[word.upper()]\n",
        "                    word = \"{\" + str(word_arpa) + \"}\"\n",
        "                except KeyError: pass\n",
        "                out = (out + \" \" + word + end_chars).strip()\n",
        "            if EOS_Token and out[-1] != \";\": out += \";\"\n",
        "            return out\n",
        "\n",
        "        def get_hifigan(MODEL_ID, conf_name):\n",
        "            # Download HiFi-GAN\n",
        "            hifigan_pretrained_model = 'hifimodel_' + conf_name\n",
        "            #gdown.download(d+MODEL_ID, hifigan_pretrained_model, quiet=False)\n",
        "\n",
        "            if MODEL_ID == 1:\n",
        "              !wget \"https://github.com/justinjohn0306/tacotron2/releases/download/assets/Superres_Twilight_33000\" -O $hifigan_pretrained_model\n",
        "            elif MODEL_ID == \"universal\":\n",
        "              !wget \"https://github.com/justinjohn0306/tacotron2/releases/download/assets/g_02500000\" -O $hifigan_pretrained_model\n",
        "            else:\n",
        "              gdown.download(d+MODEL_ID, hifigan_pretrained_model, quiet=False)\n",
        "\n",
        "            if not exists(hifigan_pretrained_model):\n",
        "                raise Exception(\"HiFI-GAN model failed to download!\")\n",
        "\n",
        "            # Load HiFi-GAN\n",
        "            conf = os.path.join(\"hifi-gan\", conf_name + \".json\")\n",
        "            with open(conf) as f:\n",
        "                json_config = json.loads(f.read())\n",
        "            h = AttrDict(json_config)\n",
        "            torch.manual_seed(h.seed)\n",
        "            hifigan = Generator(h).to(torch.device(\"cpu\"))\n",
        "            state_dict_g = torch.load(hifigan_pretrained_model, map_location=torch.device(\"cpu\"))\n",
        "            hifigan.load_state_dict(state_dict_g[\"generator\"])\n",
        "            hifigan.eval()\n",
        "            hifigan.remove_weight_norm()\n",
        "            denoiser = Denoiser(hifigan, mode=\"normal\")\n",
        "            return hifigan, h, denoiser\n",
        "\n",
        "        # Download character HiFi-GAN\n",
        "        hifigan, h, denoiser = get_hifigan(HIFIGAN_ID, \"config_v1\")\n",
        "        # Download super-resolution HiFi-GAN\n",
        "        hifigan_sr, h2, denoiser_sr = get_hifigan(1, \"config_32k\")\n",
        "        pbar.update(1) # Downloaded and Set up HiFi-GAN\n",
        "\n",
        "        def has_MMI(STATE_DICT):\n",
        "            return any(True for x in STATE_DICT.keys() if \"mi.\" in x)\n",
        "\n",
        "        def get_Tactron2(MODEL_ID):\n",
        "            # Download Tacotron2\n",
        "            tacotron2_pretrained_model = 'MLPTTS'\n",
        "            gdown.download(d+MODEL_ID, tacotron2_pretrained_model, quiet=False)\n",
        "            if not exists(tacotron2_pretrained_model):\n",
        "                raise Exception(\"Tacotron2 model failed to download!\")\n",
        "            # Load Tacotron2 and Config\n",
        "            hparams = create_hparams()\n",
        "            hparams.sampling_rate = 22050\n",
        "            hparams.max_decoder_steps = 3000 # Max Duration\n",
        "            hparams.gate_threshold = 0.25 # Model must be 25% sure the clip is over before ending generation\n",
        "            model = Tacotron2(hparams)\n",
        "            state_dict = torch.load(tacotron2_pretrained_model, map_location=torch.device(\"cpu\"))['state_dict']\n",
        "            if has_MMI(state_dict):\n",
        "                raise Exception(\"ERROR: This notebook does not currently support MMI models.\")\n",
        "            model.load_state_dict(state_dict)\n",
        "            _ = model.eval()\n",
        "            return model, hparams\n",
        "\n",
        "        model, hparams = get_Tactron2(TACOTRON2_ID)\n",
        "        previous_tt2_id = TACOTRON2_ID\n",
        "\n",
        "        pbar.update(1) # Downloaded and Set up Tacotron2\n",
        "\n",
        "        # Extra Info\n",
        "        def end_to_end_infer(text, pronounciation_dictionary, show_graphs):\n",
        "            for i in [x for x in text.split(\"\\n\") if len(x)]:\n",
        "                if not pronounciation_dictionary:\n",
        "                    if i[-1] != \";\": i=i+\";\"\n",
        "                else: i = ARPA(i)\n",
        "                with torch.no_grad(): # save VRAM by not including gradients\n",
        "                    sequence = np.array(text_to_sequence(i, ['english_cleaners']))[None, :]\n",
        "                    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).long()\n",
        "                    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "                    if show_graphs:\n",
        "                        plot_data((mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
        "                                alignments.float().data.cpu().numpy()[0].T))\n",
        "                    y_g_hat = hifigan(mel_outputs_postnet.float())\n",
        "                    audio = y_g_hat.squeeze()\n",
        "                    audio = audio * MAX_WAV_VALUE\n",
        "                    audio_denoised = denoiser(audio.view(1, -1), strength=35)[:, 0]\n",
        "\n",
        "                    # Resample to 32k\n",
        "                    audio_denoised = audio_denoised.cpu().numpy().reshape(-1)\n",
        "\n",
        "                    normalize = (MAX_WAV_VALUE / np.max(np.abs(audio_denoised))) ** 0.9\n",
        "                    audio_denoised = audio_denoised * normalize\n",
        "                    wave = resampy.resample(\n",
        "                        audio_denoised,\n",
        "                        h.sampling_rate,\n",
        "                        h2.sampling_rate,\n",
        "                        filter=\"sinc_window\",\n",
        "                        window=scipy.signal.windows.hann,\n",
        "                        num_zeros=8,\n",
        "                    )\n",
        "                    wave_out = wave.astype(np.int16)\n",
        "\n",
        "                    # HiFi-GAN super-resolution\n",
        "                    wave = wave / MAX_WAV_VALUE\n",
        "                    wave = torch.FloatTensor(wave).to(torch.device(\"cpu\"))\n",
        "                    new_mel = mel_spectrogram(\n",
        "                        wave.unsqueeze(0),\n",
        "                        h2.n_fft,\n",
        "                        h2.num_mels,\n",
        "                        h2.sampling_rate,\n",
        "                        h2.hop_size,\n",
        "                        h2.win_size,\n",
        "                        h2.fmin,\n",
        "                        h2.fmax,\n",
        "                    )\n",
        "                    y_g_hat2 = hifigan_sr(new_mel)\n",
        "                    audio2 = y_g_hat2.squeeze()\n",
        "                    audio2 = audio2 * MAX_WAV_VALUE\n",
        "                    audio2_denoised = denoiser(audio2.view(1, -1), strength=35)[:, 0]\n",
        "\n",
        "                    # High-pass filter, mixing and denormalizing\n",
        "                    audio2_denoised = audio2_denoised.cpu().numpy().reshape(-1)\n",
        "                    b = scipy.signal.firwin(\n",
        "                        101, cutoff=10500, fs=h2.sampling_rate, pass_zero=False\n",
        "                    )\n",
        "                    y = scipy.signal.lfilter(b, [1.0], audio2_denoised)\n",
        "                    y *= superres_strength\n",
        "                    y_out = y.astype(np.int16)\n",
        "                    y_padded = np.zeros(wave_out.shape)\n",
        "                    y_padded[: y_out.shape[0]] = y_out\n",
        "                    sr_mix = wave_out + y_padded\n",
        "                    sr_mix = sr_mix / normalize\n",
        "\n",
        "                    print(\"\")\n",
        "                    ipd.display(ipd.Audio(sr_mix.astype(np.int16), rate=h2.sampling_rate))\n",
        "    from IPython.display import clear_output\n",
        "    clear_output()\n",
        "    initialized = \"Ready\"\n",
        "\n",
        "if previous_tt2_id != TACOTRON2_ID:\n",
        "    print(\"Updating Models\")\n",
        "    model, hparams = get_Tactron2(TACOTRON2_ID)\n",
        "    hifigan, h, denoiser = get_hifigan(HIFIGAN_ID, \"config_v1\")\n",
        "    previous_tt2_id = TACOTRON2_ID\n",
        "\n",
        "pronounciation_dictionary = True #@param {type:\"boolean\"}\n",
        "# disables automatic ARPAbet conversion, useful for inputting your own ARPAbet pronounciations or just for testing\n",
        "show_graphs = True #@param {type:\"boolean\"}\n",
        "max_duration =  20#@param {type:\"integer\"}\n",
        "model.decoder.max_decoder_steps = max_duration * 80\n",
        "stop_threshold = 0.5 #@param {type:\"number\"}\n",
        "model.decoder.gate_threshold = stop_threshold\n",
        "superres_strength = 5 #@param {type:\"number\"}\n",
        "variable_name = \"\" # @param {type:\"string\"}\n",
        "\n",
        "print(f\"Current Config:\\npronounciation_dictionary: {pronounciation_dictionary}\\nshow_graphs: {show_graphs}\\nmax_duration (in seconds): {max_duration}\\nstop_threshold: {stop_threshold}\\nsuperres_strength: {superres_strength}\\n\\n\")\n",
        "\n",
        "time.sleep(1)\n",
        "print(\"Enter/Paste your text.\")\n",
        "contents = []\n",
        "while True:\n",
        "    try:\n",
        "        print(\"-\"*50)\n",
        "        line = input()\n",
        "        if line == \"\":\n",
        "            continue\n",
        "        end_to_end_infer(line, not pronounciation_dictionary, show_graphs)\n",
        "    except EOFError:\n",
        "        break\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Stopping...\")\n",
        "        break"
      ],
      "metadata": {
        "id": "nU8YYg6PXgjg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1e77822b11fa473bbe3113413cc2751d",
            "2aee7c5bb8d04b0c8b9250360a3273c0",
            "288885328af843a383994c6c64c2b97a",
            "7691bb49f9b64704ae278eb21c672b2c",
            "ccf4a623ace54f9a98afad55b8fb0218",
            "f9d5224ed5394ccbac2f82d8b2decf62",
            "e73c19e0097b4c8e8028cbb1ad94d7a0",
            "30bb3e9526964488a70a5e897d9b4856",
            "9d412ee453f14ad7b08ecb0cbd03e061",
            "6b63f89feaa04c29b51c43311cb683f9",
            "1baaa449b6e642ebb77d9aea95a026c9"
          ]
        },
        "outputId": "09c644bb-2ec6-4a8e-bb21-e3a1fdec2f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n",
            "Installing collected packages: resampy\n",
            "Successfully installed resampy-0.4.3\n",
            "Collecting git+https://github.com/IAHispano/gdown.git\n",
            "  Cloning https://github.com/IAHispano/gdown.git to /tmp/pip-req-build-xn91l_9l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/IAHispano/gdown.git /tmp/pip-req-build-xn91l_9l\n",
            "  Resolved https://github.com/IAHispano/gdown.git to commit 6f0bd9df3f33edc7024e55088118ddbab5ef3a27\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==0.1.dev451+g6f0bd9d) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==0.1.dev451+g6f0bd9d) (3.15.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==0.1.dev451+g6f0bd9d) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown==0.1.dev451+g6f0bd9d) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==0.1.dev451+g6f0bd9d) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==0.1.dev451+g6f0bd9d) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==0.1.dev451+g6f0bd9d) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==0.1.dev451+g6f0bd9d) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==0.1.dev451+g6f0bd9d) (2024.7.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==0.1.dev451+g6f0bd9d) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-0.1.dev451+g6f0bd9d-py3-none-any.whl size=16936 sha256=da8ce6245ceeb9a62a39ed2e3ef182e537225e7d2fc9b65644623db496e202e5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-poo3cx1d/wheels/2c/14/21/edd09e54de038de56bf7c757143c85b3834b710ae05ecc6ab2\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 5.1.0\n",
            "    Uninstalling gdown-5.1.0:\n",
            "      Successfully uninstalled gdown-5.1.0\n",
            "Successfully installed gdown-0.1.dev451+g6f0bd9d\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing universal Hifi-Gan model.\n",
            "Setting up, please wait.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e77822b11fa473bbe3113413cc2751d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2bea9bb22154>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0minitialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'initialized' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2bea9bb22154>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mhparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_hparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTacotron2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTacotronSTFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TTS-TT2/hparams.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHParamsAlternative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menv\u001b[0m \u001b[0;31m# line: 456\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate\u001b[0m \u001b[0;31m# line: 365\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0min_main_process\u001b[0m \u001b[0;31m# line: 418\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/combinations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_worker_test_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/multi_worker_test_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster_resolver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcluster_resolver_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_coordinator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitored_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserver_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrackable_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masync_checkpoint_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheckpoint_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('musab123')"
      ],
      "metadata": {
        "id": "-GKDp-pH82L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_5mLPe4S88sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "_Mm5V9tS0_Bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "qCQ5SVFz1BXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\n",
        "from google.colab import userdata\n",
        "userdata.get('secret_musab')\n",
        "\n",
        "\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "#prep\n",
        "import os\n",
        "!pip install tqdm -q\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "from os.path import exists, join, basename, splitext\n",
        "!pip install resampy\n",
        "!pip install git+https://github.com/IAHispano/gdown.git\n",
        "git_repo_url = 'https://github.com/justinjohn0306/TTS-TT2.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "# clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  !git clone -q --recursive https://github.com/justinjohn0306/hifi-gan\n",
        "  !pip install -q unidecode\n",
        "import sys\n",
        "sys.path.append('hifi-gan')\n",
        "sys.path.append(project_name)\n",
        "\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "logging.getLogger('librosa').setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "#Universal HiFi-GAN (has some robotic noise): 1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown **The \"tacotron_id\" is where you can put a link to your trained tacotron2 model from Google Drive.**\n",
        "\n",
        "\n",
        "#@markdown If the audio sounds too artificial, you can lower the superres_strength\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Config:\n",
        "\n",
        "#@markdown Restart the runtime to apply any changes.\n",
        "\n",
        "tacotron_id = \"1-NDvTKw1908NCQarMCiEkw9dSGV3VsG6\" #@param {type:\"string\"}\n",
        "\n",
        "hifigan_id = \"universal\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown _leave blank or enter \"universal\" for universal model_\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "if tacotron_id != \"\":\n",
        "    TACOTRON2_ID = tacotron_id\n",
        "else:\n",
        "    raise Exception(\"No ID provided.\")\n",
        "\n",
        "if hifigan_id in {\"\", \"universal\"}:\n",
        "    HIFIGAN_ID = \"universal\"\n",
        "    print(\"Using universal Hifi-Gan model.\")\n",
        "else:\n",
        "    HIFIGAN_ID = hifigan_id\n",
        "\n",
        "# Check if Initialized\n",
        "try:\n",
        "    initialized\n",
        "except NameError:\n",
        "    print(\"Setting up, please wait.\\n\")\n",
        "    with tqdm(total=5, leave=False) as pbar:\n",
        "\n",
        "        import time\n",
        "        import matplotlib\n",
        "        import matplotlib.pylab as plt\n",
        "        import gdown\n",
        "        d = 'https://drive.google.com/uc?id='\n",
        "\n",
        "#         %matplotlib inline\n",
        "        import IPython.display as ipd\n",
        "        import numpy as np\n",
        "        import torch\n",
        "        import json\n",
        "        from hparams import create_hparams\n",
        "        from model import Tacotron2\n",
        "        from layers import TacotronSTFT\n",
        "        from audio_processing import griffin_lim\n",
        "        from text import text_to_sequence\n",
        "        from env import AttrDict\n",
        "        from meldataset import mel_spectrogram, MAX_WAV_VALUE\n",
        "        from models import Generator\n",
        "        from denoiser import Denoiser\n",
        "        import resampy\n",
        "        import scipy.signal\n",
        "\n",
        "        pbar.update(1) # initialized Dependancies\n",
        "\n",
        "        graph_width = 900\n",
        "        graph_height = 360\n",
        "        def plot_data(data, figsize=(int(graph_width/100), int(graph_height/100))):\n",
        "#             %matplotlib inline\n",
        "            fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
        "            for i in range(len(data)):\n",
        "                axes[i].imshow(data[i], aspect='auto', origin='lower',\n",
        "                            interpolation='none', cmap='inferno')\n",
        "            fig.canvas.draw()\n",
        "            plt.show()\n",
        "\n",
        "        # Setup Pronounciation Dictionary\n",
        "        !wget 'https://github.com/justinjohn0306/FakeYou-Tacotron2-Notebook/releases/download/CMU_dict/merged.dict.txt'\n",
        "        thisdict = {}\n",
        "        for line in reversed((open('merged.dict.txt', \"r\").read()).splitlines()):\n",
        "            thisdict[(line.split(\" \",1))[0]] = (line.split(\" \",1))[1].strip()\n",
        "\n",
        "        pbar.update(1) # Downloaded and Set up Pronounciation Dictionary\n",
        "\n",
        "        def ARPA(text, punctuation=r\"!?,.;\", EOS_Token=True):\n",
        "            out = ''\n",
        "            for word_ in text.split(\" \"):\n",
        "                word=word_; end_chars = ''\n",
        "                while any(elem in word for elem in punctuation) and len(word) > 1:\n",
        "                    if word[-1] in punctuation: end_chars = word[-1] + end_chars; word = word[:-1]\n",
        "                    else: break\n",
        "                try:\n",
        "                    word_arpa = thisdict[word.upper()]\n",
        "                    word = \"{\" + str(word_arpa) + \"}\"\n",
        "                except KeyError: pass\n",
        "                out = (out + \" \" + word + end_chars).strip()\n",
        "            if EOS_Token and out[-1] != \";\": out += \";\"\n",
        "            return out\n",
        "\n",
        "        def get_hifigan(MODEL_ID, conf_name):\n",
        "            # Download HiFi-GAN\n",
        "            hifigan_pretrained_model = 'hifimodel_' + conf_name\n",
        "            #gdown.download(d+MODEL_ID, hifigan_pretrained_model, quiet=False)\n",
        "\n",
        "            if MODEL_ID == 1:\n",
        "              !wget \"https://github.com/justinjohn0306/tacotron2/releases/download/assets/Superres_Twilight_33000\" -O $hifigan_pretrained_model\n",
        "            elif MODEL_ID == \"universal\":\n",
        "              !wget \"https://github.com/justinjohn0306/tacotron2/releases/download/assets/g_02500000\" -O $hifigan_pretrained_model\n",
        "            else:\n",
        "              gdown.download(d+MODEL_ID, hifigan_pretrained_model, quiet=False)\n",
        "\n",
        "            if not exists(hifigan_pretrained_model):\n",
        "                raise Exception(\"HiFI-GAN model failed to download!\")\n",
        "\n",
        "            # Load HiFi-GAN\n",
        "            conf = os.path.join(\"hifi-gan\", conf_name + \".json\")\n",
        "            with open(conf) as f:\n",
        "                json_config = json.loads(f.read())\n",
        "            h = AttrDict(json_config)\n",
        "            torch.manual_seed(h.seed)\n",
        "            hifigan = Generator(h).to(torch.device(\"cpu\"))\n",
        "            state_dict_g = torch.load(hifigan_pretrained_model, map_location=torch.device(\"cpu\"))\n",
        "            hifigan.load_state_dict(state_dict_g[\"generator\"])\n",
        "            hifigan.eval()\n",
        "            hifigan.remove_weight_norm()\n",
        "            denoiser = Denoiser(hifigan, mode=\"normal\")\n",
        "            return hifigan, h, denoiser\n",
        "\n",
        "        # Download character HiFi-GAN\n",
        "        hifigan, h, denoiser = get_hifigan(HIFIGAN_ID, \"config_v1\")\n",
        "        # Download super-resolution HiFi-GAN\n",
        "        hifigan_sr, h2, denoiser_sr = get_hifigan(1, \"config_32k\")\n",
        "        pbar.update(1) # Downloaded and Set up HiFi-GAN\n",
        "\n",
        "        def has_MMI(STATE_DICT):\n",
        "            return any(True for x in STATE_DICT.keys() if \"mi.\" in x)\n",
        "\n",
        "        def get_Tactron2(MODEL_ID):\n",
        "            # Download Tacotron2\n",
        "            tacotron2_pretrained_model = 'MLPTTS'\n",
        "            gdown.download(d+MODEL_ID, tacotron2_pretrained_model, quiet=False)\n",
        "            if not exists(tacotron2_pretrained_model):\n",
        "                raise Exception(\"Tacotron2 model failed to download!\")\n",
        "            # Load Tacotron2 and Config\n",
        "            hparams = create_hparams()\n",
        "            hparams.sampling_rate = 22050\n",
        "            hparams.max_decoder_steps = 3000 # Max Duration\n",
        "            hparams.gate_threshold = 0.25 # Model must be 25% sure the clip is over before ending generation\n",
        "            model = Tacotron2(hparams)\n",
        "            state_dict = torch.load(tacotron2_pretrained_model, map_location=torch.device(\"cpu\"))['state_dict']\n",
        "            if has_MMI(state_dict):\n",
        "                raise Exception(\"ERROR: This notebook does not currently support MMI models.\")\n",
        "            model.load_state_dict(state_dict)\n",
        "            _ = model.eval()\n",
        "            return model, hparams\n",
        "\n",
        "        model, hparams = get_Tactron2(TACOTRON2_ID)\n",
        "        previous_tt2_id = TACOTRON2_ID\n",
        "\n",
        "        pbar.update(1) # Downloaded and Set up Tacotron2\n",
        "\n",
        "        # Extra Info\n",
        "        def end_to_end_infer(text, pronounciation_dictionary, show_graphs):\n",
        "            for i in [x for x in text.split(\"\\n\") if len(x)]:\n",
        "                if not pronounciation_dictionary:\n",
        "                    if i[-1] != \";\": i=i+\";\"\n",
        "                else: i = ARPA(i)\n",
        "                with torch.no_grad(): # save VRAM by not including gradients\n",
        "                    sequence = np.array(text_to_sequence(i, ['english_cleaners']))[None, :]\n",
        "                    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).long()\n",
        "                    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "                    if show_graphs:\n",
        "                        plot_data((mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
        "                                alignments.float().data.cpu().numpy()[0].T))\n",
        "                    y_g_hat = hifigan(mel_outputs_postnet.float())\n",
        "                    audio = y_g_hat.squeeze()\n",
        "                    audio = audio * MAX_WAV_VALUE\n",
        "                    audio_denoised = denoiser(audio.view(1, -1), strength=35)[:, 0]\n",
        "\n",
        "                    # Resample to 32k\n",
        "                    audio_denoised = audio_denoised.cpu().numpy().reshape(-1)\n",
        "\n",
        "                    normalize = (MAX_WAV_VALUE / np.max(np.abs(audio_denoised))) ** 0.9\n",
        "                    audio_denoised = audio_denoised * normalize\n",
        "                    wave = resampy.resample(\n",
        "                        audio_denoised,\n",
        "                        h.sampling_rate,\n",
        "                        h2.sampling_rate,\n",
        "                        filter=\"sinc_window\",\n",
        "                        window=scipy.signal.windows.hann,\n",
        "                        num_zeros=8,\n",
        "                    )\n",
        "                    wave_out = wave.astype(np.int16)\n",
        "\n",
        "                    # HiFi-GAN super-resolution\n",
        "                    wave = wave / MAX_WAV_VALUE\n",
        "                    wave = torch.FloatTensor(wave).to(torch.device(\"cpu\"))\n",
        "                    new_mel = mel_spectrogram(\n",
        "                        wave.unsqueeze(0),\n",
        "                        h2.n_fft,\n",
        "                        h2.num_mels,\n",
        "                        h2.sampling_rate,\n",
        "                        h2.hop_size,\n",
        "                        h2.win_size,\n",
        "                        h2.fmin,\n",
        "                        h2.fmax,\n",
        "                    )\n",
        "                    y_g_hat2 = hifigan_sr(new_mel)\n",
        "                    audio2 = y_g_hat2.squeeze()\n",
        "                    audio2 = audio2 * MAX_WAV_VALUE\n",
        "                    audio2_denoised = denoiser(audio2.view(1, -1), strength=35)[:, 0]\n",
        "\n",
        "                    # High-pass filter, mixing and denormalizing\n",
        "                    audio2_denoised = audio2_denoised.cpu().numpy().reshape(-1)\n",
        "                    b = scipy.signal.firwin(\n",
        "                        101, cutoff=10500, fs=h2.sampling_rate, pass_zero=False\n",
        "                    )\n",
        "                    y = scipy.signal.lfilter(b, [1.0], audio2_denoised)\n",
        "                    y *= superres_strength\n",
        "                    y_out = y.astype(np.int16)\n",
        "                    y_padded = np.zeros(wave_out.shape)\n",
        "                    y_padded[: y_out.shape[0]] = y_out\n",
        "                    sr_mix = wave_out + y_padded\n",
        "                    sr_mix = sr_mix / normalize\n",
        "\n",
        "                    print(\"\")\n",
        "                    ipd.display(ipd.Audio(sr_mix.astype(np.int16), rate=h2.sampling_rate))\n",
        "    from IPython.display import clear_output\n",
        "    clear_output()\n",
        "    initialized = \"Ready\"\n",
        "\n",
        "if previous_tt2_id != TACOTRON2_ID:\n",
        "    print(\"Updating Models\")\n",
        "    model, hparams = get_Tactron2(TACOTRON2_ID)\n",
        "    hifigan, h, denoiser = get_hifigan(HIFIGAN_ID, \"config_v1\")\n",
        "    previous_tt2_id = TACOTRON2_ID\n",
        "\n",
        "pronounciation_dictionary = True #@param {type:\"boolean\"}\n",
        "# disables automatic ARPAbet conversion, useful for inputting your own ARPAbet pronounciations or just for testing\n",
        "show_graphs = True #@param {type:\"boolean\"}\n",
        "max_duration =  20#@param {type:\"integer\"}\n",
        "model.decoder.max_decoder_steps = max_duration * 80\n",
        "stop_threshold = 0.5 #@param {type:\"number\"}\n",
        "model.decoder.gate_threshold = stop_threshold\n",
        "superres_strength = 5 #@param {type:\"number\"}\n",
        "variable_name = \"\" # @param {type:\"string\"}\n",
        "\n",
        "print(f\"Current Config:\\npronounciation_dictionary: {pronounciation_dictionary}\\nshow_graphs: {show_graphs}\\nmax_duration (in seconds): {max_duration}\\nstop_threshold: {stop_threshold}\\nsuperres_strength: {superres_strength}\\n\\n\")\n",
        "\n",
        "time.sleep(1)\n",
        "print(\"Enter/Paste your text.\")\n",
        "contents = []\n",
        "while True:\n",
        "    try:\n",
        "        print(\"-\"*50)\n",
        "        line = input()\n",
        "        if line == \"\":\n",
        "            continue\n",
        "        end_to_end_infer(line, not pronounciation_dictionary, show_graphs)\n",
        "    except EOFError:\n",
        "        break\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Stopping...\")\n",
        "        break\n",
        "\n",
        "from google.colab import userdata\n",
        "userdata.get('musab123')\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"# New Section\n",
        "\n",
        "# New Section\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(musab123')\n",
        "\n",
        "')"
      ],
      "metadata": {
        "id": "rzskDx80yXXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RGoLn_0-1JSF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}